{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import psycopg2\r\n",
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def loadDataAndCreateColumns(file, STUDYNAME):\r\n",
    "    '''\r\n",
    "    This function loads a csv file and parses the column types to generate a dictionary of PostgreSQL data types and a parsed dataframe.\r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    ---------- \r\n",
    "    file : str, path to the csv file. \r\n",
    "    '''\r\n",
    "    \r\n",
    "    df = pd.read_csv(file, sep=None, engine = 'python')\r\n",
    "    iterator = pd.read_csv(file, sep=None, engine = 'python', iterator=True) # To check the csv formating\r\n",
    "    inferredDelimiter = iterator._engine.data.dialect.delimiter \r\n",
    "    print(f'File delimiter is {inferredDelimiter}\\n') # Prints the csv delimiter\r\n",
    "    df.rename(columns={list(df)[0]: df.columns[0].replace(\"\\ufeff\", \"\")}, inplace = True) # Removes '\\ufeff' from the first column name\r\n",
    "    df.columns = df.columns.str.replace(\"&\", \"and\").str.replace(\"-\", \"_\") # Replaces some characters due to incompatibility with SQL naming schemes\r\n",
    "    \r\n",
    "    df['uniqueIdentifier'] = df.id.apply(lambda r: f'{STUDYNAME}_{r}') # Find the column named 'id' and creates a new one as a unique identifier by adding the study name\r\n",
    "    \r\n",
    "    dtypeDict = dict()\r\n",
    "    for c in df.columns:\r\n",
    "        msk = df[c].notna()\r\n",
    "        df.loc[msk, c] = pd.to_numeric(df.loc[msk, c].astype(str).str.replace(',', '.'), errors=\"ignore\") # Convert strings to numeric\r\n",
    "        if df[c].dtype in (np.int64, np.int32, int, float, bool): # Preparing for parsing check\r\n",
    "            if df[c].dtype in (np.int32, np.int64) or df[msk][c].apply(float.is_integer).all(): # If after NaN removal all the floats end in .0, the column dtype is int\r\n",
    "                df.loc[msk, c] = df.loc[msk, c].astype(int)\r\n",
    "                if set(df[c].dropna().unique()) == {0, 1}: # If they have only 0 and 1 as values, the column is bool\r\n",
    "                    df[c] = df[c].astype(bool)\r\n",
    "                    dtypeDict[c] = 'bool'\r\n",
    "                else:\r\n",
    "                    dtypeDict[c] = 'int'\r\n",
    "            else:\r\n",
    "                dtypeDict[c] = 'float' # If not every number ends in .0, then dtype is float\r\n",
    "        else:\r\n",
    "            dtypeDict[c] = \"text\" # If none of those conditions are met, the dtype is object (SQL dtype)\r\n",
    "    for k, v in dtypeDict.items():\r\n",
    "        if v == 'int':\r\n",
    "            df[k] = df[k].astype(str).str.replace('\\.0$', '') # Remove the .0 from the integers\r\n",
    "            df = df.replace('nan', np.nan) # Reconvert the NaN to the proper dtype\r\n",
    "             \r\n",
    "    return df, dtypeDict\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def createTable(columnDict, TABLENAME):\r\n",
    "    '''\r\n",
    "    Creates an SQL table by reading a dictionary of columns:dtype.\r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    columnDict : dict, dictionary of columns with corresponding data type.\r\n",
    "    TABLENAME : str, name of the table.\r\n",
    "    ''' \r\n",
    "    columns = \"(\" + \",\\n\".join([f\"{k} {v}\" for k,v in columnDict.items()]) + \")\" # Creating the columns for the table\r\n",
    "    \r\n",
    "    conn = psycopg2.connect(\"host=localhost dbname=test user=postgres password=test123\")\r\n",
    "    cur = conn.cursor()\r\n",
    "    cur.execute(f\"CREATE TABLE {TABLENAME} \\n {columns}\")\r\n",
    "    conn.commit()\r\n",
    "    cur.close()\r\n",
    "    conn.close()\r\n",
    "\r\n",
    "    \r\n",
    "def addData(file, TABLENAME):\r\n",
    "\r\n",
    "    conn = psycopg2.connect(\"host=localhost dbname=test user=postgres password=test123\")\r\n",
    "    cur = conn.cursor()\r\n",
    "    with open(file, 'r') as f:\r\n",
    "        next(f) # Skip the header row.\r\n",
    "        cur.copy_from(f, TABLENAME.lower(), sep=';', null =\"\")\r\n",
    "    conn.commit()\r\n",
    "    cur.close()\r\n",
    "    conn.close()\r\n",
    "    \r\n",
    "\r\n",
    "def dropTable(TABLENAME):\r\n",
    "    conn = psycopg2.connect(\"host=localhost dbname=test user=postgres password=test123\")\r\n",
    "    cur = conn.cursor()\r\n",
    "    cur.execute(f'DROP TABLE {TABLENAME.lower()};')\r\n",
    "    conn.commit()\r\n",
    "    cur.close()\r\n",
    "    conn.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dataPath = '../csvTest'\r\n",
    "file = [os.path.join(f'{dataPath}/{d}/{f}') for d in os.listdir(f'{dataPath}') if os.path.isdir(f'{dataPath}/{d}') for f in os.listdir(f'{dataPath}/{d}') if '.csv' in f]\r\n",
    "\r\n",
    "for f in file:\r\n",
    "    STUDYNAME = f.split('/')[2]\r\n",
    "    TABLENAME = f.split('/')[3].removesuffix('.csv')\r\n",
    "\r\n",
    "    conn = psycopg2.connect(\"host=localhost dbname=test user=postgres password=test123\")\r\n",
    "    cur = conn.cursor()\r\n",
    "    cur.execute(f\"\"\"SELECT to_regclass('public.{TABLENAME.lower()}');\"\"\")\r\n",
    "    tableCheck = cur.fetchone()[0]\r\n",
    "    cur.close()\r\n",
    "    conn.close()\r\n",
    "    \r\n",
    "    if TABLENAME.lower() == tableCheck:\r\n",
    "        dropTable(TABLENAME)\r\n",
    "         \r\n",
    "        df, dtDict = loadDataAndCreateColumns(f, STUDYNAME) \r\n",
    "        endFile = f'{f[:-4]}_autogenerated.csv' \r\n",
    "        df.to_csv(endFile, index = False, sep = ';')\r\n",
    "\r\n",
    "        createTable(dtDict, TABLENAME)\r\n",
    "        addData(endFile, TABLENAME)\r\n",
    "        os.remove(endFile)\r\n",
    "    else:\r\n",
    "        try:\r\n",
    "            df, dtDict = loadDataAndCreateColumns(f, STUDYNAME)\r\n",
    "        except:\r\n",
    "            print(f'The formatting for table {f} is not right. Ignoring it and continuing.')\r\n",
    "            continue\r\n",
    "        endFile = f'{f[:-4]}_autogenerated.csv' \r\n",
    "        df.to_csv(endFile, index = False, sep = ';')\r\n",
    "\r\n",
    "        createTable(dtDict, TABLENAME)\r\n",
    "        addData(endFile, TABLENAME)\r\n",
    "        \r\n",
    "        os.remove(endFile)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File delimiter is ,\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\gpjos\\AppData\\Local\\Temp/ipykernel_26928/401354299.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[k] = df[k].astype(str).str.replace('\\.0$', '')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File delimiter is ,\n",
      "\n",
      "File delimiter is ;\n",
      "\n",
      "The formatting for table ../csvTest/testStudy/gripTest.csv is not right. Ignoring it and continuing.\n",
      "File delimiter is ;\n",
      "\n",
      "File delimiter is ;\n",
      "\n",
      "File delimiter is ;\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlImporter",
   "language": "python",
   "name": "sqlimporter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}